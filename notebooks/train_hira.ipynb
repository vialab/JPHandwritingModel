{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hira = np.load(\"datasets/hiragana/hiragana.npz\")['arr_0'].reshape([-1, 127, 128]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(hira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hira = hira/np.max(hira)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 71 characters, 160 writers, transform image to 48*48\n",
    "train_images = np.zeros([71 * 160, 48, 48], dtype=np.float32)\n",
    "\n",
    "for i in range(71 * 160):\n",
    "    train_images[i] = skimage.transform.resize(hira[i], (48, 48))\n",
    "\n",
    "arr = np.arange(71)\n",
    "train_labels = np.repeat(arr, 160) # create labels\n",
    "\n",
    "# split to train and test\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"hiragana_train_images.npz\", train_images)\n",
    "np.savez_compressed(\"hiragana_train_labels.npz\", train_labels)\n",
    "np.savez_compressed(\"hiragana_test_images.npz\", test_images)\n",
    "np.savez_compressed(\"hiragana_test_labels.npz\", test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(\"datasets/hiragana/hiragana_train_images.npz\")['arr_0']\n",
    "train_labels = np.load(\"datasets/hiragana/hiragana_train_labels.npz\")['arr_0']\n",
    "test_images = np.load(\"datasets/hiragana/hiragana_test_images.npz\")['arr_0']\n",
    "test_labels = np.load(\"datasets/hiragana/hiragana_test_labels.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == \"channels_first\":\n",
    "  train_images = train_images.reshape(train_images.shape[0], 1,48,48)\n",
    "  test_images2 = test_images.reshape(test_images.shape[0], 1,48,48)\n",
    "  shape = (1,48,48)\n",
    "else:\n",
    "  train_images = train_images.reshape(train_images.shape[0], 48, 48, 1)\n",
    "  test_images2 = test_images.reshape(test_images.shape[0], 48, 48, 1)\n",
    "  shape = (48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 23, 23, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 21, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 71)                72775     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1196871 (4.57 MB)\n",
      "Trainable params: 1196871 (4.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=15,zoom_range=0.2)\n",
    "datagen.fit(train_images)\n",
    "\n",
    "model = keras.Sequential([\n",
    "  keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=shape),\n",
    "  keras.layers.MaxPooling2D(2,2),\n",
    "  keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(2,2),\n",
    "  keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(2,2),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dropout(0.5),\n",
    "  keras.layers.Dense(1024, activation='relu'),\n",
    "  keras.layers.Dense(71, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29639/29902955.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(train_images,train_labels,shuffle=True),epochs=30,validation_data=(test_images2,test_labels),callbacks = [keras.callbacks.EarlyStopping(patience=8,verbose=1,restore_best_weights=True),keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3,verbose=1)])\n",
      "2024-02-19 18:10:09.732084: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-02-19 18:10:10.255075: I external/local_xla/xla/service/service.cc:168] XLA service 0x5d9e5a1a7f50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-19 18:10:10.255090: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Ti, Compute Capability 8.9\n",
      "2024-02-19 18:10:10.262098: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708384210.324790   46158 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 3s 4ms/step - loss: 2.3172 - accuracy: 0.3983 - val_loss: 0.6464 - val_accuracy: 0.7923 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.8656 - accuracy: 0.7379 - val_loss: 0.2914 - val_accuracy: 0.9093 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.5705 - accuracy: 0.8231 - val_loss: 0.2520 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.8567 - val_loss: 0.1706 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.3577 - accuracy: 0.8873 - val_loss: 0.1074 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.3056 - accuracy: 0.9024 - val_loss: 0.1585 - val_accuracy: 0.9467 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.2680 - accuracy: 0.9164 - val_loss: 0.0838 - val_accuracy: 0.9754 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.2453 - accuracy: 0.9215 - val_loss: 0.1029 - val_accuracy: 0.9621 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.2125 - accuracy: 0.9306 - val_loss: 0.1888 - val_accuracy: 0.9401 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.9334 - val_loss: 0.0795 - val_accuracy: 0.9762 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1778 - accuracy: 0.9400 - val_loss: 0.0814 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9432 - val_loss: 0.0795 - val_accuracy: 0.9736 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1711 - accuracy: 0.9443 - val_loss: 0.0571 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1526 - accuracy: 0.9492 - val_loss: 0.0629 - val_accuracy: 0.9820 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1446 - accuracy: 0.9538 - val_loss: 0.0508 - val_accuracy: 0.9842 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1441 - accuracy: 0.9522 - val_loss: 0.0460 - val_accuracy: 0.9850 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1287 - accuracy: 0.9571 - val_loss: 0.0546 - val_accuracy: 0.9820 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9584 - val_loss: 0.0462 - val_accuracy: 0.9855 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "280/284 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9604\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.9601 - val_loss: 0.0663 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 0.0433 - val_accuracy: 0.9850 - lr: 5.0000e-04\n",
      "Epoch 21/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0730 - accuracy: 0.9758 - val_loss: 0.0456 - val_accuracy: 0.9837 - lr: 5.0000e-04\n",
      "Epoch 22/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.9781 - val_loss: 0.0353 - val_accuracy: 0.9899 - lr: 5.0000e-04\n",
      "Epoch 23/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.0280 - val_accuracy: 0.9903 - lr: 5.0000e-04\n",
      "Epoch 24/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9787 - val_loss: 0.0455 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 25/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.0423 - val_accuracy: 0.9877 - lr: 5.0000e-04\n",
      "Epoch 26/30\n",
      "282/284 [============================>.] - ETA: 0s - loss: 0.0606 - accuracy: 0.9818\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9818 - val_loss: 0.0373 - val_accuracy: 0.9868 - lr: 5.0000e-04\n",
      "Epoch 27/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9826 - val_loss: 0.0301 - val_accuracy: 0.9881 - lr: 2.5000e-04\n",
      "Epoch 28/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9850 - val_loss: 0.0307 - val_accuracy: 0.9886 - lr: 2.5000e-04\n",
      "Epoch 29/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 0.0260 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "Epoch 30/30\n",
      "284/284 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.0231 - val_accuracy: 0.9908 - lr: 2.5000e-04\n",
      "71/71 [==============================] - 0s 957us/step - loss: 0.0231 - accuracy: 0.9908\n",
      "Test Accuracy:  0.9907570481300354\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(datagen.flow(train_images,train_labels,shuffle=True),epochs=30,validation_data=(test_images2,test_labels),callbacks = [keras.callbacks.EarlyStopping(patience=8,verbose=1,restore_best_weights=True),keras.callbacks.ReduceLROnPlateau(factor=0.5,patience=3,verbose=1)])\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images2, test_labels)\n",
    "print(\"Test Accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/hiragana_1.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
